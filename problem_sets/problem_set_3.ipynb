{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b0d30161-faaf-4d38-aa97-4a0c80e648d3",
      "metadata": {},
      "source": [
        "# ECON526: Assignment 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aec4255-01e1-43e9-b14a-becee7f76b10",
      "metadata": {},
      "source": [
        "## Student Name/Number: Ryan Quek (81771206)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f86a457d-6635-444b-acf0-a1bdaf860286",
      "metadata": {},
      "source": [
        "### Instructions\n",
        "\n",
        "-   Ensure you modify the field above with your **name and student\n",
        "    number above immediately**\n",
        "-   Modify directly and save as the `.ipynb`, and submit directly. Do\n",
        "    not export to PDF or HTML, and leave the filename as is. Canvas will\n",
        "    automatically append your name to the filename.\n",
        "-   Submit directly to canvas as a `.ipynb` file.\n",
        "\n",
        "## Setup\n",
        "\n",
        "Feel free to use the following packages (and we have added a few\n",
        "convenience imports)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "94b52649",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from numpy.linalg import cond, matrix_rank, norm\n",
        "from scipy.linalg import inv, solve, det, eig, lu, eigvals\n",
        "from scipy.linalg import solve_triangular, eigvalsh, cholesky"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ee63de-d736-43de-ae7a-faf39388c806",
      "metadata": {},
      "source": [
        "## Q1.1\n",
        "\n",
        "Prove that if you have an eigendecomposition of $A = Q \\Lambda Q^{-1}$,\n",
        "then $A \\cdot A = A^2 = Q \\Lambda^2 Q^{-1}$ where $\\Lambda^2$ is the\n",
        "componentwise square of the eigenvalues. Hint: use the fact that the $Q$\n",
        "is orthonormal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958f5835-9beb-499b-90d6-dddac1c94281",
      "metadata": {},
      "source": [
        "$A \\cdot A = A^2 $\n",
        "\n",
        "$A \\cdot A = (Q \\Lambda Q^{-1})^2 $\n",
        "\n",
        "$A \\cdot A = (Q \\Lambda Q^{-1}) \\cdot (Q \\Lambda Q^{-1}) $\n",
        "\n",
        "By associative multiplication\n",
        "\n",
        "$A \\cdot A = (Q \\Lambda( Q^{-1} Q) \\Lambda Q^{-1}) $\n",
        "\n",
        "Since $Q \\cdot Q^{-1} = I$ (Q is orthonormal) this means that: \n",
        "\n",
        "$A \\cdot A = (Q \\Lambda I \\Lambda Q^{-1}) $\n",
        "\n",
        "ie. $A \\cdot A = (Q \\Lambda \\Lambda Q^{-1}) = (Q \\Lambda^2 Q^{-1}) $\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "448f04f8-e9ce-4626-8b0e-b297d657136d",
      "metadata": {},
      "source": [
        "## Q1.2\n",
        "\n",
        "There is nothing special in part 1.1 about taking the square. Just as\n",
        "you would define the square root of a number $x$ as a $x^{1/2}$ such\n",
        "that $x^{1/2} \\times x^{1/2} = x$, we can do the same thing with a\n",
        "matrix square root $A^{1/2}$ is such that $A^{1/2} \\cdot A^{1/2} = A$.\n",
        "\n",
        "Use the eigendecomposition and take inspiration from part Q1.1 to find\n",
        "$A^{1/2}$ for the $A$ given below. Verify that\n",
        "$A^{1/2} \\cdot A^{1/2} \\approx A$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bb3ba027",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2. 1.]\n",
            " [1. 2.]]\n"
          ]
        }
      ],
      "source": [
        "A = np.array([[2, 1], [1, 2]])\n",
        "# modify here to calculate A^{1/2}, i.e. where A^{1/2} A^{1/2} = A\n",
        "\n",
        "Asqrt = np.sqrt(A)\n",
        "\n",
        "Acheck = Asqrt*Asqrt\n",
        "print(Acheck)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c5256c",
      "metadata": {},
      "source": [
        "From above, Since variable Acheck which is the $A^{1/2} \\cdot A^{1/2}$ equals A, $A^{1/2} \\cdot A^{1/2} \\approx A$ is proven"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a9cd15-8e16-4ac2-9722-a2ae017e399d",
      "metadata": {},
      "source": [
        "## Q1.3\n",
        "\n",
        "Consider that both $(-2)\\times(-2) = 2 \\times 2 = 4$. There may be\n",
        "multiple square roots of a matrix, and many matrices do not have a\n",
        "square root. For example, For example, the matrix\n",
        "$A = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$ does not have a\n",
        "square root.\n",
        "\n",
        "Take this matrix and mention a property of it that suggests why this\n",
        "matrix looks suspicious and does not have a unique square root or why\n",
        "the method might fail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a1f57f99",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EigResult(eigenvalues=array([0., 0.]), eigenvectors=array([[ 1.00000000e+000, -1.00000000e+000],\n",
            "       [ 0.00000000e+000,  2.00416836e-292]]))\n",
            "[[2 3]\n",
            " [2 2]]\n"
          ]
        }
      ],
      "source": [
        "A = np.array([[0, 1], [0, 0]])\n",
        "# modify here, add comments and an explanation on what the problems here would be\n",
        "print(np.linalg.eig(A))\n",
        "#Eigenvalues are 0. This means that Matrix is not positive definite.\n",
        "matrix_rank(A)\n",
        "#The matrix is not full rank either\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e58f75-69c4-4fb4-8b24-d8d8f85ff352",
      "metadata": {},
      "source": [
        "## Q1.4\n",
        "\n",
        "Argue that if a matrix is symmetric positive definite then its square\n",
        "root will also be symmetric, positive definite."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71c1c70-f91f-4dff-9f4d-de11b46bb39c",
      "metadata": {},
      "source": [
        "A symmetric positive definite matrix has a positive eigenvalue. Similarly, its square root would therefore be positive. This means that when you do a spectral decomposition, you will get a positive definite matrix. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97a6ec4-88d0-45be-82f9-e7f9c6602bf7",
      "metadata": {},
      "source": [
        "## Q2.1\n",
        "\n",
        "Take a random variable with the multivariate normal distribution\n",
        "\n",
        "$$\n",
        "Y \\sim N(\\mu, \\Sigma)\n",
        "$$\n",
        "\n",
        "with $\\mu \\equiv \\begin{bmatrix} 0 \\\\ 1\\end{bmatrix}$ and\n",
        "$\\Sigma \\equiv \\begin{bmatrix} 0.1 & 0.05 \\\\ 0.05 & 0.1 \\end{bmatrix}$\n",
        "\n",
        "Take 10,000 draws using this distribution. Hint: See\n",
        "`np.random.multivariate_normal` in the lecture notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "98f52018",
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 10000\n",
        "mu = np.array([0, 1])\n",
        "sigma = np.array([[0.1, 0.05], [0.05, 0.1]])\n",
        "Y_draws = np.random.multivariate_normal(mu, sigma, N)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d11f8cf5-0b39-48f1-877e-59ba8427a20a",
      "metadata": {},
      "source": [
        "## Q2.2\n",
        "\n",
        "Take the `Y_draws` above, calculate the mean and covariance matrix, and\n",
        "compare them to $\\mu$ and $\\Sigma$ to see how close they are. Hint: use\n",
        "`np.cov(Y_draws, rowvar=False)` to get the covariance matrix. What is a\n",
        "natural way to compare how close matrices or vectors are?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "18a58152",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of Y_draws = 0.5034250861102548, Covariance of Y_draws = [[0.099483   0.05064271]\n",
            " [0.05064271 0.10292711]]\n"
          ]
        }
      ],
      "source": [
        "Y_drawsmean = np.mean(Y_draws)\n",
        "Y_drawscov = np.cov(Y_draws,rowvar=False)\n",
        "\n",
        "np.mean(mu)\n",
        "\n",
        "print(f'Mean of Y_draws = {Y_drawsmean}, Covariance of Y_draws = {Y_drawscov}')\n",
        "# make sure to state how you are comparing vectors/matrices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "988affdd-68ad-44cb-a6bb-8046ead705e6",
      "metadata": {},
      "source": [
        "For vectors, it would be to take the midpoint (by euclidean distance) between the two numbers.\n",
        "For matrices, you could just simply compare the matrix.\n",
        "\n",
        "In this case, the euclidean distance of Y_draws is 1, which means the midpoint would be 0.5, \n",
        "which turns out to be the mean of Y_draws"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca93972-c078-41ba-bee8-59abc9fda9ea",
      "metadata": {},
      "source": [
        "## Q2.3\n",
        "\n",
        "A key property of Gaussian random variables is that for any\n",
        "$Y \\sim N(\\mu, \\Sigma)$ we can write it as a function of a unit\n",
        "multivariate normal $X \\sim N(0, I)$ and a matrix $A$ such that\n",
        "$Y = \\mu + C X$. This is called the Cholesky decomposition of $\\Sigma$.\n",
        "\n",
        "1.  Find the Cholesky of the covariance matrix $\\Sigma$, $C$. You can\n",
        "    use upper or lower Cholesky, but be consistent\n",
        "2.  Draw the same $N$ number of draws from $X \\sim N(0,I)$ as the\n",
        "    previous parts of Q2\n",
        "3.  Transform those draws $Y$\n",
        "4.  Compare the mean and covariance of those transformed $Y$ to $\\mu$\n",
        "    and $\\Sigma$ to see how well the transformation did"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "51d83f98",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.31540925 0.        ]\n",
            " [0.16056191 0.27775347]]\n",
            "Mean of Y_draws = 0.5034250861102548, Covariance of Y_draws = [[0.099483   0.05064271]\n",
            " [0.05064271 0.10292711]]\n",
            "Mean of X = 0.5008222701939411, Covariance of X = [[0.10054867 0.0516744 ]\n",
            " [0.0516744  0.10375625]]\n"
          ]
        }
      ],
      "source": [
        "#Cholesky\n",
        "C = cholesky(Y_drawscov, lower=True) # cholesky also defined for upper=True\n",
        "\n",
        "I = np.array([[1,0],[0,1]])\n",
        "mu1=np.array([0,0])\n",
        "X_draws = np.random.multivariate_normal(mu1, I, N)\n",
        "\n",
        "X_drawsmat = mu + X_draws @ C.T\n",
        "\n",
        "X_drawsmean = np.mean(X_drawsmat)\n",
        "X_drawscov = np.cov(X_drawsmat,rowvar=False)\n",
        "\n",
        "print(f'Mean of Y_draws = {Y_drawsmean}, Covariance of Y_draws = {Y_drawscov}')\n",
        "print(f'Mean of X = {X_drawsmean}, Covariance of X = {X_drawscov}')\n",
        "\n",
        "#Pretty much the same!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33ca427a-5a76-43ec-822d-1400981b5ee9",
      "metadata": {},
      "source": [
        "## Q2.4\n",
        "\n",
        "The same transformation works with the matrix square root. That is, if\n",
        "$Y \\sim N(\\mu, \\Sigma)$, then $Y = \\mu + \\Sigma^{1/2} X$ where\n",
        "$X \\sim N(0, I)$ where $\\Sigma^{1/2}$ is the matrix square root of\n",
        "$\\Sigma$.\n",
        "\n",
        "Repeat the Q2.3 using this transformation instead. That is,\n",
        "\n",
        "1.  Find the square root of the covariance matrix $\\Sigma$,\n",
        "    $\\Sigma^{1/2}$. Hint: You can do this yourself using previous\n",
        "    sections, use the `scipy` function `scipy.linalg.sqrtm` or use the\n",
        "    scipy function `scipy.linalg.matrix_power` with the argument `0.5`.\n",
        "2.  Draw the same $N$ number of draws from $X \\sim N(0,I)$ as the\n",
        "    previous parts of Q2\n",
        "3.  Transform those draws to form $Y$ samples\n",
        "4.  Compare the mean and covariance of those transformed $Y$ to $\\mu$\n",
        "    and $\\Sigma$ to see how well the transformation did"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "3f8a9cec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of Y_draws = 0.4983977175586157, Covariance of Y_draws = [[0.10164906 0.05080894]\n",
            " [0.05080894 0.09930455]]\n",
            "Mean of current draw = 0.5006645302300483, Covariance of current draw = [[0.10029164 0.04964506]\n",
            " [0.04964506 0.0995219 ]]\n"
          ]
        }
      ],
      "source": [
        "sqrtsigma=scipy.linalg.sqrtm(sigma)\n",
        "newdraw = np.random.multivariate_normal(mu1, I, N)\n",
        "\n",
        "newdrawmat = mu + newdraw @ sqrtsigma.T\n",
        "\n",
        "newdrawmean = np.mean(newdrawmat)\n",
        "newdrawcov = np.cov(newdrawmat,rowvar=False)\n",
        "\n",
        "print(f'Mean of Y_draws = {Y_drawsmean}, Covariance of Y_draws = {Y_drawscov}')\n",
        "print(f'Mean of current draw = {newdrawmean}, Covariance of current draw = {newdrawcov}')\n",
        "\n",
        "#Like Q2.3, it matches quite close to the original Y_draws that we have."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0920bd78-65f7-4f67-99dc-4af07c54f637",
      "metadata": {},
      "source": [
        "## Q3.1\n",
        "\n",
        "Take a new mean $\\mu$ and covariance matrix, $\\Sigma$. You want to do\n",
        "the same thing as previous examples (i.e., find a matrix, $A$ such that\n",
        "$Y = \\mu + A X$ for $X \\sim N(0,I)$).\n",
        "\n",
        "Take the matrix below, its eigenvalues, and the results of calling\n",
        "Cholesky. Explain why you probably shouldnâ€™t be using it in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "003c1306",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[9.30949336e-01 0.00000000e+00 0.00000000e+00]\n",
            " [7.51920618e-01 3.58057437e-02 0.00000000e+00]\n",
            " [2.14834462e-01 1.43222975e-01 5.20193130e-08]]\n",
            "Eigenvalues(Sigma) = [-9.29420474e-17  1.95131000e-02  1.48048690e+00]\n"
          ]
        }
      ],
      "source": [
        "mu = np.array([0, 1, 1])\n",
        "Sigma = np.array([\n",
        "    [26, 21, 6],\n",
        "    [21, 17, 5],\n",
        "    [6, 5, 2]\n",
        "]) / 30.0\n",
        "C = cholesky(Sigma, lower=True)\n",
        "print(C)\n",
        "print(f\"Eigenvalues(Sigma) = {eigvalsh(Sigma)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae1969b3-021d-4c8e-8ad0-2987cb4a2b8d",
      "metadata": {},
      "source": [
        "One of the eigenvalues is negative, which indicates that the matrix is not positive definite. Cholesky decompositions can only be done on positive definite matrices, therefore calling the cholesky is not a good idea, as the results would not be sensible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee4f25c-1f6a-409f-9aea-8d29f71954e3",
      "metadata": {},
      "source": [
        "## Q3.2\n",
        "\n",
        "The Cholesky is suspicious, but what about the matrix square root?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "821a4d42",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sigma^sqrt = \n",
            "[[0.7208559 +4.03468980e-09j 0.57388853-5.37958640e-09j\n",
            "  0.13298645+1.34489660e-09j]\n",
            " [0.57388853-5.37958640e-09j 0.4659534 +7.17278187e-09j\n",
            "  0.14214799-1.79319547e-09j]\n",
            " [0.13298645+1.34489660e-09j 0.14214799-1.79319547e-09j\n",
            "  0.16963261+4.48298867e-10j]]\n",
            "Sigma^sqrt real only = \n",
            "[[0.7208559  0.57388853 0.13298645]\n",
            " [0.57388853 0.4659534  0.14214799]\n",
            " [0.13298645 0.14214799 0.16963261]]\n"
          ]
        }
      ],
      "source": [
        "Sigma_sqrt = scipy.linalg.sqrtm(Sigma)\n",
        "print(f\"Sigma^sqrt = \\n{Sigma_sqrt}\")\n",
        "print(f\"Sigma^sqrt real only = \\n{np.real(Sigma_sqrt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f9fde93-0300-43a1-b16f-3b6448228744",
      "metadata": {},
      "source": [
        "Any comments on whether this would be a reasonable way to transform the\n",
        "random variable into a $Y = \\mu + \\Sigma^{1/2} X$ for $X \\sim N(0,I)$?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baad1d23-7679-422e-ab4e-b68b2fae8d05",
      "metadata": {},
      "source": [
        "Taking the real component only would not be reasonable as some information is being lost due to the imaginary numbers. Although it may sometimes return reasonable answers, it may not be the advisable method to do going forward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "299ce01e-7e7e-414e-979f-69c66256b423",
      "metadata": {},
      "source": [
        "## Q3.3\n",
        "\n",
        "Your friend suggests trying an SVD of the covariance matrix, which is\n",
        "always defined. Here are the results for $U S V^T = \\Sigma$,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "357ab144",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "U =\n",
            " [[-0.76451208  0.26337697  0.58834841]\n",
            " [-0.61865349 -0.04339637 -0.78446454]\n",
            " [-0.18107771 -0.96371641  0.19611614]]\n",
            "S =\n",
            " [1.48048690e+00 1.95131000e-02 8.63766899e-18]\n",
            "V' =\n",
            " [[-0.76451208 -0.61865349 -0.18107771]\n",
            " [ 0.26337697 -0.04339637 -0.96371641]\n",
            " [-0.58834841  0.78446454 -0.19611614]]"
          ]
        }
      ],
      "source": [
        "U, S, Vh = scipy.linalg.svd(Sigma) # returns V' not V\n",
        "print(f\"U =\\n {U}\")\n",
        "print(f\"S =\\n {S}\")\n",
        "print(f\"V' =\\n {Vh}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af2fbe1-82e4-465e-987d-488cff5da0f1",
      "metadata": {},
      "source": [
        "Your friend then shows you the following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "02872f0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape(A) = (3, 2)\n",
            "A =\n",
            "[[-0.93022207  0.03679094]\n",
            " [-0.75274824 -0.00606201]\n",
            " [-0.22032678 -0.13462087]]\n",
            "A @ A.T =\n",
            "[[0.86666667 0.7        0.2       ]\n",
            " [0.7        0.56666667 0.16666667]\n",
            " [0.2        0.16666667 0.06666667]]\n",
            "||A A' - Sigma|| = 9.899056296961976e-16"
          ]
        }
      ],
      "source": [
        "U_truncated = U[:, :2] # truncating to only use the first two columns\n",
        "S_truncated = np.diag(np.sqrt(S[:2])) # first two singular values\n",
        "A = U_truncated @ S_truncated # using first two singular values\n",
        "print(f\"shape(A) = {A.shape}\")\n",
        "print(f\"A =\\n{A}\")\n",
        "print(f\"A @ A.T =\\n{A @ A.T}\")\n",
        "print(f\"||A A' - Sigma|| = {norm(A @ A.T - Sigma)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1673102a-1828-43c2-b9a9-4906d617c985",
      "metadata": {},
      "source": [
        "Can you explain why this is a great observation and how it might be\n",
        "useful for transforming the random variable $Y = \\mu + A \\hat{X}$ for\n",
        "some unit normal $\\hat{X}$?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d8446f-ca89-41b8-b4df-4109e6eb4231",
      "metadata": {},
      "source": [
        "SVD does not require the matrix to be positive definite, hence it will come in useful here when the matrix is not positive definite. You can also reduce the dimensions, and get largely similar results, making for faster results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1194168d-25c0-4567-b676-2499a886a74c",
      "metadata": {},
      "source": [
        "## Q3.4\n",
        "\n",
        "Finally, your friend uses this to generate a bunch of random values to\n",
        "check if the random variable works relative to the original and compares\n",
        "the sqrt version to the new one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4fafc7b5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "||mean(Y_draws) - mu|| = 0.0063334498268498626\n",
            "||mean(Y_draws_sqrt) - mu|| = 0.003121888360609609\n",
            "||mean(Y_draws_hat) - mu|| = 0.002828313767585362\n",
            "||cov(Y_draws) - Sigma|| = 0.009876578761824174\n",
            "||cov(Y_draws_sqrt) - Sigma|| = 0.004347592590831399\n",
            "||cov(Y_draws_hat) - Sigma|| = 0.002501262475879615"
          ]
        }
      ],
      "source": [
        "N = 100000\n",
        "Y_draws = np.random.multivariate_normal(mu,Sigma, size=N) # unit normal\n",
        "X_draws = np.random.multivariate_normal(np.zeros(3), np.eye(3), size=N) # unit normal\n",
        "Y_draws_sqrt = mu + X_draws @ Sigma_sqrt.T # sqrt version\n",
        "X_hat_draws = np.random.multivariate_normal(np.zeros(2), np.eye(2), size=N) # unit normal\n",
        "Y_draws_hat = mu + X_hat_draws @ A.T # Using the A from the SVD\n",
        "print(f\"||mean(Y_draws) - mu|| = {norm(np.mean(Y_draws, axis=0) - mu)}\")\n",
        "print(f\"||mean(Y_draws_sqrt) - mu|| = {norm(np.mean(Y_draws_sqrt, axis=0) - mu)}\")\n",
        "print(f\"||mean(Y_draws_hat) - mu|| = {norm(np.mean(Y_draws_hat, axis=0) - mu)}\")\n",
        "print(f\"||cov(Y_draws) - Sigma|| = {norm(np.cov(Y_draws, rowvar=False) - Sigma)}\")\n",
        "print(f\"||cov(Y_draws_sqrt) - Sigma|| = {norm(np.cov(Y_draws_sqrt, rowvar=False) - Sigma)}\")\n",
        "print(f\"||cov(Y_draws_hat) - Sigma|| = {norm(np.cov(Y_draws_hat, rowvar=False) - Sigma)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a7388ab-d86d-44d7-ba8e-bc42780612cc",
      "metadata": {},
      "source": [
        "This worked great. In fact, simulating with the new processes seems\n",
        "almost better than directly using the $Y$ but your friend is confused.\n",
        "When they simulated `Y_draws` and `Y_draws_sqrt` they were drawing\n",
        "3-dimensional random normals, but when they did `Y_draws_hat` it was\n",
        "only 2-dimensional. How can this be and still deliver the same results?\n",
        "Explain it to your friend."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f803845a-3aa2-4225-881a-41bad1fc185d",
      "metadata": {},
      "source": [
        "The 2 dimensional Y_draws_hat was actually multiplied by the transpose of A, which is a 2x3 matrix. This in effect made Y_draws_hat a 3 dimensional calculation. As such, the results would have been similar to the other simulated 3 dimensional random normals."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
